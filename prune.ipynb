{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3d46a6c9a5b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from model_creator import make_conv2d_model, mod\n",
    "import tensorly as tl\n",
    "import tensorly.decomposition as dc\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import scale, normalize\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import Sequential, Conv2d\n",
    "tl.set_backend('pytorch')\n",
    "device='cpu'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['n_conv_layers'] = 1\n",
    "params['use_batch_norm'] = False\n",
    "params['input_kernel_size'] = (5, 5)\n",
    "params['conv_dim_change'] = 'double'\n",
    "params['pool_size'] = (2, 2)\n",
    "params['activation'] = 'relu'\n",
    "params['n_dense_layers'] = 0\n",
    "params['conv_kernel_size'] = (3, 3)\n",
    "params['initial_kernel_number'] = 15\n",
    "params['dense_dim'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = mod(*make_conv2d_model((3, 32, 32), 10, params)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.wide_resnet50_2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "model.fc = torch.nn.Linear(2048, 200)\n",
    "experiment = 303\n",
    "seed = 303\n",
    "model_id = f\"{experiment}_{seed}\"\n",
    "model_path = Path(f\"outputs/experiment_{experiment}/data/{model_id}\").rglob('*pt')\n",
    "model_path = list(model_path)[0]\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "print('loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = [model.conv1]\n",
    "for sequential in [model.layer1, model.layer2, model.layer3, model.layer4]:\n",
    "    for bottleneck in sequential:\n",
    "        b = bottleneck\n",
    "        conv_layers.extend([bottleneck.conv1, bottleneck.conv2, bottleneck.conv3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bottleneck(\n",
       "  (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-ab36d0cb81a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbneck_layers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "ls = [a for a in dir(b) if a in bneck_layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vips(pls_model):\n",
    "    t = pls_model.x_scores_\n",
    "    w = pls_model.x_weights_\n",
    "    q = pls_model.y_loadings_\n",
    "    p, h = w.shape\n",
    "    vips = np.zeros((p,))\n",
    "    s = np.diag(np.matmul(np.matmul(np.matmul(t.T,t),q.T), q)).reshape(h, -1)\n",
    "    total_s = np.sum(s)\n",
    "    for i in range(p):\n",
    "        weight = np.array([ (w[i,j] / np.linalg.norm(w[:,j]))**2 for j in range(h) ])\n",
    "        vips[i] = np.sqrt(p*(np.matmul(s.T, weight))/total_s)\n",
    "    return vips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedKFold(n_splits=4, n_repeats=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bneck_layers = ['conv1', 'bn1', 'conv2', 'bn2', 'conv3', 'bn3', 'relu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "data_dir = Path('tiny-imagenet-200')\n",
    "data_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4805, 0.4483, 0.3978), (0.263, 0.257, 0.267)),\n",
    "])\n",
    "valid_set = torchvision.datasets.ImageFolder(data_dir / 'val', data_transforms)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=batch_size,\n",
    "                                           shuffle=False, pin_memory=True)\n",
    "train_set = torchvision.datasets.ImageFolder(data_dir / 'train', data_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
    "                                           shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_filters(model, valid_loader, valid_set, remove_percent, device):\n",
    "    \"\"\"\n",
    "    worst : list of highest divergence filters (worst filters) across batches\n",
    "            Can select top-k afterwards.\n",
    "    imp   : list of divergences from tensor decomposition reconstruction.\n",
    "            lower means filter is more important.\n",
    "    \"\"\"\n",
    "    worst = []\n",
    "    model.eval()\n",
    "    num_layers = 0\n",
    "    for i, data in tqdm(enumerate(valid_loader),\n",
    "                        total=len(valid_set) / valid_loader.batch_size):\n",
    "        out, y = data\n",
    "        out = out.to(device)\n",
    "        y = y\n",
    "        sizes = []\n",
    "        num_lay = 0\n",
    "        for j, (name, param) in enumerate(model.named_children()):\n",
    "            if name in ['avgpool', 'layer3']:\n",
    "                break\n",
    "            if type(param) == Sequential:\n",
    "                for bottle in param:\n",
    "                    for b in bneck_layers:\n",
    "                        out = getattr(bottle, b)(out)\n",
    "                        if b in ['conv1', 'conv2', 'conv3']:\n",
    "                            nout = out.detach().clone()\n",
    "                            num_rem = int(nout.shape[1] * remove_percent)\n",
    "                            cp = dc.tucker(nout, 15)\n",
    "                            pred = tl.tucker_tensor.tucker_to_tensor(cp)\n",
    "                            dist = torch.cdist(pred, nout)\n",
    "                            importance = torch.mean(dist, dim=[0, 2, 3])\n",
    "                            _, w = torch.topk(importance, num_rem)\n",
    "                            worst.append(w)\n",
    "                            num_lay += 1\n",
    "                            \n",
    "            else:\n",
    "                out = param(out)\n",
    "                if type(param) == Conv2d:\n",
    "                    nout = out.detach().clone()\n",
    "                    num_rem = int(nout.shape[1] * remove_percent)\n",
    "                    cp = dc.tucker(nout, 15)\n",
    "                    pred = tl.tucker_tensor.tucker_to_tensor(cp)\n",
    "                    dist = torch.cdist(pred, nout)\n",
    "                    importance = torch.mean(dist, dim=[0, 2, 3])\n",
    "                    _, w = torch.topk(importance, num_rem)\n",
    "                    worst.append(w)\n",
    "                    num_lay += 1\n",
    "        if i * valid_loader.batch_size >= 100:\n",
    "            num_layers = num_lay\n",
    "            break\n",
    "    return worst, num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/312.5 [00:10<54:51, 10.57s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-974037174466>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mworst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_lay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_filters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-a11e7f94285f>\u001b[0m in \u001b[0;36mselect_filters\u001b[0;34m(model, valid_loader, valid_set, remove_percent)\u001b[0m\n\u001b[1;32m     26\u001b[0m                             \u001b[0mnout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                             \u001b[0mnum_rem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mremove_percent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                             \u001b[0mcp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtucker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtucker_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtucker_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                             \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorly/decomposition/_tucker.py\u001b[0m in \u001b[0;36mtucker\u001b[0;34m(tensor, rank, fixed_factors, n_iter_max, init, svd, tol, random_state, mask, verbose)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         core, factors = partial_tucker(tensor, modes, rank=rank, n_iter_max=n_iter_max, init=init,\n\u001b[0;32m--> 206\u001b[0;31m                             svd=svd, tol=tol, random_state=random_state, mask=mask, verbose=verbose)\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mTuckerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorly/decomposition/_tucker.py\u001b[0m in \u001b[0;36mpartial_tucker\u001b[0;34m(tensor, modes, rank, n_iter_max, init, tol, svd, random_state, verbose, mask)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mfactors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0meigenvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_eigenvecs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0mfactors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meigenvecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorly/backend/core.py\u001b[0m in \u001b[0;36mpartial_svd\u001b[0;34m(self, matrix, n_eigenvecs, random_state, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdim_1\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mdim_2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m                 S, U = scipy.sparse.linalg.eigsh(\n\u001b[0;32m--> 908\u001b[0;31m                     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_eigenvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'LM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m                 )\n\u001b[1;32m    910\u001b[0m                 \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "worst, num_lay = select_filters(model, valid_loader, valid_set, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_filt = []\n",
    "for i in range(num_lay):\n",
    "    bad_filt.append(worst[i::num_lay])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62, 47, 8, 31, 3, 25, 53, 10, 21, 58, 29, 11, 43, 61, 54, 63, 16, 49, 42, 48, 28, 5, 7, 60, 40, 6, 12, 41, 9, 44, 2, 45, 32, 4, 39, 55, 34] ,\n",
      "[70, 51, 99, 7, 6, 43, 75, 47, 56, 44, 120, 4, 21, 100, 86, 62, 26, 109, 10, 39, 54, 110, 0, 46, 61, 123, 35, 79, 22, 117, 9, 96, 63, 14, 32, 59, 104, 115, 119, 5, 36, 57, 121, 82, 60, 19, 125, 64, 73, 88, 34, 106, 89, 95, 42, 65, 27, 102, 45, 127, 101, 50, 68, 81, 13, 2, 17, 97] ,\n",
      "[82, 56, 11, 48, 12, 54, 77, 118, 5, 3, 26, 20, 58, 55, 24, 126, 23, 42, 127, 2, 35, 29, 124, 97, 63, 22, 81, 33, 78, 90, 17, 83, 101, 93, 70, 27, 1, 85, 79, 37, 46, 87, 86, 18, 38, 84, 15, 64, 75, 59, 9, 116, 112, 28, 61, 51, 73, 94, 123, 74, 109, 71, 120, 66, 105, 43, 57, 92] ,\n",
      "[135, 118, 107, 152, 40, 128, 186, 167, 240, 156, 143, 223, 216, 102, 196, 133, 109, 154, 103, 96, 6, 72, 211, 251, 146, 105, 125, 244, 238, 44, 37, 90, 120, 218, 115, 67, 53, 101, 246, 57, 91, 199, 13, 39, 5, 68, 197, 208, 229, 41, 226, 108, 7, 34, 235, 88, 159, 81, 248, 54, 230, 155, 180, 73, 78, 75, 183, 214, 93, 148, 220, 60, 198, 110, 70, 193, 187, 86, 179, 1, 174, 25, 147, 83, 80, 184, 100, 30, 224, 206, 190, 19, 131, 22, 111, 202, 94, 51, 85, 9, 161, 241, 170, 112, 66, 232, 163, 2, 176, 194, 33, 89, 213, 172, 104, 35, 113, 177, 233, 31, 192, 136, 157, 228, 254, 150, 231, 71, 203, 17, 250, 219, 52, 65] ,\n",
      "[95, 111, 4, 22, 104, 46, 114, 91, 14, 9, 25, 107, 8, 69, 99, 41, 62, 127, 36, 39, 16, 109, 117, 92, 3, 82, 88, 61, 45, 87, 35, 13, 0, 73, 10, 105, 15, 125, 96, 49, 52, 70, 65, 120, 51, 89, 20, 21, 110, 100, 5, 7, 27, 48, 32, 68, 11, 79, 6, 116, 44, 12, 101, 123, 40, 43, 83, 124, 85, 98, 77, 28, 74] ,\n",
      "[70, 119, 25, 100, 94, 39, 91, 103, 8, 126, 23, 54, 60, 74, 73, 116, 12, 22, 105, 16, 114, 53, 13, 71, 31, 21, 5, 30, 49, 14, 18, 110, 97, 113, 88, 29, 124, 11, 92, 43, 98, 28, 89, 120, 84, 51, 95, 6, 112, 104, 80, 64, 56, 75, 48, 99, 102, 33, 109, 115, 59, 1, 15, 118, 108, 44, 65, 50, 47, 46, 122] ,\n",
      "[203, 98, 80, 0, 199, 96, 239, 218, 166, 157, 146, 176, 150, 73, 27, 90, 13, 143, 180, 115, 102, 86, 179, 230, 37, 220, 188, 173, 190, 29, 81, 100, 178, 116, 171, 7, 255, 60, 99, 117, 162, 15, 233, 224, 163, 226, 227, 74, 217, 58, 144, 159, 36, 22, 97, 184, 33, 245, 17, 153, 228, 66, 31, 83, 174, 42, 65, 136, 16, 194, 82, 95, 71, 142, 214, 160, 164, 49, 234, 93, 213, 200, 177, 202, 88, 249, 250, 121, 77, 155, 30, 172, 151, 221, 205, 104, 168, 23, 114, 111, 2, 10, 147, 252, 247, 51, 50, 192, 89, 123, 183, 131, 195, 243, 45, 138, 52, 91, 20, 12, 63, 25, 219, 85, 62, 87, 48, 204, 126, 21, 254, 130, 113, 61, 106, 170, 18] ,\n",
      "[126, 20, 89, 27, 7, 86, 79, 66, 3, 110, 74, 28, 107, 125, 16, 100, 90, 99, 67, 64, 32, 45, 36, 76, 102, 60, 46, 121, 4, 58, 109, 11, 50, 47, 112, 85, 62, 95, 37, 39, 53, 97, 22, 31, 122, 49, 115, 111, 84, 51, 117, 71, 17, 5, 12, 57, 75, 68, 127, 104, 69, 82, 73, 54, 88, 113, 77, 52, 119, 0, 118, 29] ,\n",
      "[112, 24, 82, 38, 0, 20, 18, 87, 109, 121, 54, 26, 10, 47, 48, 104, 118, 79, 8, 105, 13, 57, 32, 75, 45, 37, 90, 96, 23, 120, 29, 94, 78, 98, 76, 106, 102, 36, 59, 116, 25, 33, 9, 58, 15, 93, 50, 68, 49, 119, 89, 113, 95, 28, 114, 43, 56, 65, 127, 92, 4, 1, 41, 3, 126, 66, 107, 88, 124, 17, 7, 14] ,\n",
      "[22, 65, 15, 100, 179, 255, 217, 133, 71, 74, 169, 174, 102, 82, 182, 208, 145, 37, 20, 225, 12, 110, 29, 228, 134, 25, 162, 36, 116, 138, 195, 87, 66, 233, 131, 118, 157, 52, 104, 210, 139, 214, 96, 61, 183, 137, 207, 124, 185, 215, 158, 113, 171, 194, 126, 117, 2, 227, 26, 184, 204, 212, 127, 163, 31, 79, 129, 192, 173, 147, 122, 11, 95, 221, 245, 249, 106, 77, 4, 76, 17, 92, 209, 90, 243, 46, 156, 236, 32, 213, 112, 230, 48, 42, 28, 62, 234, 18, 202, 111, 136, 153, 121, 99, 189, 130, 177, 252, 190, 164, 119, 10, 175, 33, 50, 168, 21, 3, 151, 51, 247, 150, 7, 98, 224, 159, 149, 55, 181, 45, 123] ,\n",
      "[95, 113, 56, 78, 255, 250, 127, 74, 210, 197, 108, 121, 103, 22, 31, 24, 12, 129, 37, 222, 184, 115, 244, 154, 216, 81, 238, 193, 240, 30, 220, 84, 117, 194, 125, 82, 114, 183, 209, 77, 229, 1, 92, 48, 203, 170, 55, 94, 0, 232, 111, 13, 49, 10, 71, 246, 185, 16, 18, 254, 171, 128, 87, 25, 73, 202, 9, 3, 42, 45, 65, 146, 27, 76, 211, 79, 105, 242, 116, 251, 83, 17, 201, 126, 234, 139, 188, 155, 75, 120, 50, 248, 153, 198, 165, 28, 122, 182, 80, 177, 110, 207, 104, 54, 96, 196, 237, 157, 47, 23, 159, 253, 137, 70, 245, 195, 178, 145, 247, 179, 191, 33, 63, 109, 144, 86, 218, 123, 212, 43, 88, 35, 192, 20, 7, 228, 136, 221, 143, 85, 99, 41, 119, 36] ,\n",
      "[82, 89, 95, 63, 246, 179, 129, 218, 70, 204, 18, 111, 227, 207, 80, 225, 251, 200, 199, 27, 226, 174, 16, 81, 103, 213, 72, 155, 2, 206, 166, 21, 247, 125, 102, 42, 239, 49, 236, 173, 136, 0, 202, 210, 138, 169, 126, 83, 215, 94, 150, 76, 203, 92, 188, 119, 205, 115, 88, 245, 26, 228, 23, 241, 132, 248, 186, 108, 59, 71, 11, 168, 39, 167, 24, 65, 163, 232, 153, 84, 157, 252, 242, 201, 104, 14, 106, 19, 90, 184, 175, 130, 181, 148, 144, 1, 182, 139, 244, 37, 219, 183, 87, 54, 158, 190, 194, 224, 160, 43, 185, 195, 110, 142, 235, 35, 48, 33, 75, 50, 197, 74, 38, 154, 10, 64, 40, 159, 45, 146, 209, 77, 91, 34, 53, 22, 109, 145, 198, 12, 189, 123, 98, 161, 172, 151, 101, 250, 8, 238, 25, 220, 121, 208, 176, 68, 124, 51, 187, 93, 143, 170, 28, 17, 191] ,\n",
      "[468, 492, 277, 303, 353, 157, 365, 231, 481, 223, 508, 200, 262, 119, 66, 96, 35, 124, 479, 29, 291, 227, 182, 235, 245, 485, 473, 382, 44, 145, 260, 296, 345, 472, 56, 259, 130, 188, 169, 401, 362, 22, 67, 268, 194, 174, 427, 319, 411, 278, 423, 436, 160, 429, 216, 41, 378, 384, 455, 377, 360, 101, 434, 25, 248, 476, 461, 50, 403, 108, 258, 304, 310, 489, 138, 204, 334, 202, 116, 77, 110, 457, 388, 90, 415, 496, 168, 53, 128, 65, 46, 16, 495, 355, 294, 431, 179, 224, 137, 23, 402, 348, 37, 6, 313, 97, 444, 466, 501, 72, 366, 69, 321, 357, 143, 171, 148, 446, 488, 453, 87, 9, 408, 11, 462, 75, 386, 239, 454, 100, 441, 79, 58, 269, 167, 302, 102, 409, 418, 424, 132, 340, 253, 274, 105, 207, 61, 376, 435, 120, 80, 351, 19, 34, 279, 47, 288, 173, 74, 420, 270, 393, 89, 104, 500, 507, 234, 238, 151, 8, 251, 232, 192, 375, 385, 54, 184, 85, 33, 106, 337, 229, 299, 354, 247, 12, 21, 261, 275, 144, 483, 452, 380, 475, 450, 341, 228, 2, 127, 212, 31, 17, 185, 112, 68, 158, 330, 471, 371, 333, 109, 422, 482, 478, 379, 287, 324, 86, 509, 84, 358, 45, 426, 126, 312, 59, 73, 464, 469, 203, 494, 252, 322, 484, 451, 15, 13, 419, 502, 10, 383, 24, 505, 243, 397, 92, 440, 325, 432, 111, 48, 198, 256, 328, 249, 162, 400, 226, 271, 323, 177, 421, 254, 332, 165, 449, 265, 474, 331, 308, 311, 425] ,\n",
      "[109, 29, 145, 234, 100, 123, 16, 3, 193, 149, 178, 210, 200, 141, 136, 20, 214, 203, 47, 11, 15, 58, 183, 242, 132, 140, 190, 120, 124, 61, 98, 170, 82, 180, 215, 144, 14, 60, 135, 133, 116, 43, 196, 206, 143, 241, 30, 250, 81, 68, 218, 75, 52, 62, 111, 74, 65, 72, 117, 127, 246, 232, 230, 172, 39, 237, 188, 88, 213, 171, 76, 73, 209, 56, 139, 23, 94, 42, 186, 18, 105, 1, 189, 184, 163, 255, 118, 64, 191, 115, 148, 177, 211, 225, 220, 32, 251, 45, 198, 236, 231, 0, 204, 176, 201, 107, 179, 252, 138, 239, 240, 12, 33, 221, 219, 53, 207, 121, 125, 93, 106, 142, 166, 217, 158, 134, 51, 83, 137, 147, 86, 195, 22, 26, 182, 155, 28, 185] ,\n",
      "[2, 227, 37, 17, 99, 186, 82, 161, 125, 217, 6, 79, 149, 249, 29, 18, 31, 135, 49, 193, 68, 115, 22, 45, 202, 250, 170, 46, 27, 225, 150, 20, 246, 76, 33, 30, 137, 103, 223, 255, 66, 143, 239, 127, 177, 247, 93, 71, 228, 169, 108, 188, 19, 4, 42, 121, 91, 234, 113, 204, 171, 162, 168, 63, 164, 208, 160, 232, 199, 205, 15, 12, 184, 41, 101, 56, 254, 35, 40, 34, 218, 85, 21, 216, 229, 83, 198, 95, 157, 178, 222, 241, 58, 104, 159, 9, 211, 210, 132, 221, 182, 147, 233, 44, 123, 80, 73, 140, 124, 16, 153, 0, 55, 138, 65, 141, 253, 148, 142, 175, 130, 7, 163, 116, 77, 203, 106, 146, 213, 28, 94, 166, 174, 109, 243, 190, 119, 183] ,\n",
      "[300, 112, 293, 478, 414, 445, 397, 437, 338, 83, 498, 26, 477, 313, 257, 191, 149, 335, 140, 196, 373, 382, 428, 470, 347, 320, 133, 103, 148, 252, 316, 357, 306, 404, 315, 159, 71, 113, 496, 447, 153, 281, 11, 175, 42, 368, 323, 391, 265, 363, 350, 164, 263, 506, 210, 237, 480, 123, 349, 430, 247, 392, 147, 284, 417, 449, 459, 92, 266, 337, 152, 208, 215, 309, 344, 7, 369, 197, 387, 405, 44, 282, 118, 98, 236, 91, 443, 314, 195, 339, 260, 211, 126, 20, 171, 511, 141, 406, 490, 190, 213, 117, 298, 25, 451, 286, 398, 183, 484, 390, 30, 264, 61, 361, 81, 297, 396, 389, 279, 36, 308, 45, 131, 176, 242, 217, 105, 413, 87, 78, 38, 249, 121, 63, 439, 150, 442, 143, 186, 200, 111, 27, 318, 385, 94, 487, 225, 109, 214, 199, 272, 90, 13, 394, 255, 461, 216, 170, 375, 181, 259, 57, 465, 420, 376, 364, 142, 129, 456, 295, 70, 201, 167, 221, 156, 374, 467, 503, 356, 381, 377, 50, 82, 39, 62, 209, 343, 409, 433, 99, 139, 399, 383, 33, 206, 218, 219, 49, 173, 448, 28, 234, 291, 52, 0, 416, 55, 329, 292, 253, 3, 128, 305, 462, 340, 285, 486, 510, 231, 59, 254, 223, 155, 269, 110, 458, 222, 18, 500, 182, 476, 365, 468, 453, 88, 410, 169, 464, 163, 493, 438, 432, 299, 479, 302, 232, 319, 280, 366, 114, 488, 66, 95, 69, 35, 54, 307, 393, 321] ,\n",
      "[81, 254, 66, 78, 14, 38, 74, 140, 215, 89, 129, 95, 60, 105, 144, 196, 162, 155, 151, 83, 218, 230, 152, 160, 88, 112, 130, 175, 40, 168, 54, 223, 199, 117, 58, 32, 143, 159, 194, 71, 176, 99, 171, 134, 184, 50, 185, 250, 225, 100, 227, 174, 165, 72, 33, 147, 200, 35, 80, 157, 101, 246, 109, 198, 57, 124, 77, 125, 53, 73, 2, 87, 121, 242, 142, 166, 235, 113, 69, 188, 181, 158, 197, 11, 148, 91, 122, 226, 139, 5, 216, 6, 249, 231, 96, 19, 42, 126, 154, 247, 116, 65, 244, 161, 119, 111, 93, 251, 43, 146, 106, 24, 135, 212, 49, 167, 207, 16, 253, 208, 56, 82, 179, 209, 9, 255, 36, 190, 118, 149, 47, 238, 62, 173, 59, 136] ,\n",
      "[50, 132, 71, 134, 199, 24, 106, 101, 1, 129, 165, 45, 107, 5, 11, 158, 188, 184, 26, 169, 97, 54, 176, 151, 240, 59, 205, 247, 209, 160, 90, 241, 17, 111, 232, 25, 200, 148, 162, 23, 145, 18, 231, 75, 38, 56, 108, 191, 234, 36, 100, 34, 211, 139, 152, 217, 194, 166, 65, 193, 190, 85, 2, 86, 102, 19, 66, 212, 224, 10, 57, 254, 140, 216, 123, 149, 143, 110, 63, 180, 46, 156, 133, 60, 8, 179, 138, 44, 219, 70, 170, 87, 185, 6, 214, 218, 223, 52, 119, 117, 27, 155, 181, 196, 249, 113, 105, 127, 29, 213, 82, 9, 4, 215, 28, 16, 0, 253, 157, 198, 109, 79, 252, 208, 64, 248, 226, 192, 96, 12, 164, 222, 72, 98, 250, 204, 243, 173] ,\n",
      "[131, 37, 125, 467, 40, 7, 166, 331, 14, 73, 5, 357, 265, 72, 478, 330, 284, 307, 208, 255, 164, 49, 340, 200, 309, 276, 480, 382, 328, 26, 449, 61, 74, 191, 329, 258, 86, 13, 337, 215, 317, 397, 202, 288, 380, 498, 181, 497, 135, 107, 292, 323, 453, 414, 19, 283, 46, 347, 465, 301, 313, 184, 408, 391, 154, 394, 358, 404, 169, 496, 474, 133, 98, 249, 303, 148, 499, 201, 118, 27, 407, 209, 39, 511, 455, 263, 420, 144, 243, 308, 79, 179, 348, 207, 336, 463, 285, 157, 192, 161, 334, 297, 295, 9, 36, 434, 257, 168, 59, 44, 211, 259, 66, 231, 22, 282, 321, 490, 233, 298, 300, 346, 177, 376, 150, 109, 502, 294, 11, 155, 388, 165, 482, 409, 483, 142, 371, 237, 116, 35, 75, 275, 71, 101, 234, 293, 290, 439, 352, 370, 279, 500, 256, 333, 318, 134, 267, 6, 443, 204, 43, 424, 185, 403, 289, 421, 78, 398, 62, 105, 67, 123, 422, 178, 494, 119, 69, 85, 261, 466, 93, 222, 187, 23, 41, 341, 343, 106, 127, 379, 385, 10, 90, 17, 25, 364, 392, 170, 136, 296, 229, 492, 198, 339, 52, 505, 0, 188, 457, 431, 146, 314, 462, 212, 368, 481, 236, 132, 214, 260, 447, 445, 386, 84, 452, 8, 96, 510, 121, 446, 88, 186, 47, 412, 384, 126, 102, 399, 167, 310, 225, 440, 203, 114, 507, 230, 60, 48, 274, 459, 423, 213, 302, 270, 199, 435, 2, 473, 504, 327, 437, 244, 104, 103, 430, 350, 506, 264, 319, 418, 271] ,\n",
      "[64, 21, 222, 171, 29, 197, 198, 57, 238, 92, 78, 210, 218, 41, 125, 139, 98, 58, 141, 160, 129, 219, 33, 143, 104, 91, 247, 179, 178, 236, 32, 202, 162, 157, 94, 241, 180, 7, 90, 86, 203, 191, 213, 201, 221, 95, 216, 206, 252, 74, 60, 42, 6, 75, 243, 27, 131, 235, 84, 167, 151, 229, 105, 248, 164, 70, 152, 30, 225, 107, 156, 93, 102, 209, 52, 142, 249, 136, 96, 168, 138, 54, 24, 250, 100, 47, 204, 97, 195, 192, 121, 177, 118, 215, 150, 61, 134, 18, 11, 55, 115, 50, 69, 207, 23, 81, 146, 82, 45, 253, 196, 67, 65, 83, 43, 28, 9, 187, 214, 37, 239, 87, 173, 165, 220, 233, 51, 39, 72, 255, 185, 126, 154, 119, 242, 181, 223, 17, 251] ,\n",
      "[51, 94, 251, 216, 148, 70, 173, 188, 46, 83, 132, 81, 16, 86, 175, 244, 137, 235, 32, 87, 34, 75, 164, 215, 49, 72, 194, 9, 239, 78, 39, 58, 247, 3, 245, 196, 2, 225, 112, 68, 136, 213, 146, 106, 238, 240, 131, 63, 90, 5, 59, 232, 153, 224, 227, 15, 4, 120, 33, 8, 18, 206, 229, 180, 138, 236, 127, 103, 217, 105, 201, 134, 129, 104, 11, 1, 163, 24, 219, 116, 60, 80, 214, 178, 17, 117, 183, 25, 152, 166, 203, 84, 36, 0, 140, 230, 54, 143, 76, 185, 243, 242, 82, 52, 192, 110, 135, 126, 195, 211, 128, 121, 35, 210, 197, 204, 64, 165, 182, 55, 29, 222, 102, 221, 186, 255, 226, 159, 101, 65, 155, 74, 27, 156, 118, 133, 150, 23, 250, 67] ,\n",
      "[292, 125, 180, 249, 346, 1, 66, 72, 243, 173, 131, 450, 201, 258, 41, 89, 233, 336, 489, 115, 48, 107, 424, 495, 7, 493, 46, 359, 294, 331, 174, 165, 288, 435, 0, 246, 395, 12, 179, 145, 154, 401, 67, 504, 135, 193, 457, 273, 68, 305, 328, 205, 463, 415, 192, 36, 241, 22, 118, 23, 80, 274, 269, 408, 386, 451, 203, 250, 106, 418, 202, 481, 93, 198, 454, 431, 54, 502, 383, 31, 358, 47, 231, 384, 84, 452, 169, 227, 477, 421, 164, 329, 86, 499, 111, 109, 325, 78, 275, 323, 345, 85, 188, 77, 40, 419, 290, 385, 496, 508, 144, 271, 444, 177, 105, 10, 212, 422, 204, 134, 362, 289, 30, 310, 60, 207, 342, 326, 15, 507, 8, 334, 124, 471, 473, 469, 333, 59, 287, 505, 255, 127, 239, 446, 308, 148, 234, 132, 348, 24, 108, 402, 224, 388, 509, 19, 379, 184, 440, 453, 426, 490, 485, 351, 370, 389, 260, 297, 119, 376, 307, 494, 338, 380, 403, 304, 244, 357, 101, 319, 158, 324, 425, 146, 98, 420, 296, 279, 130, 299, 232, 13, 313, 235, 245, 301, 33, 500, 104, 261, 327, 226, 272, 191, 44, 503, 230, 317, 482, 151, 488, 295, 128, 474, 341, 434, 43, 136, 247, 270, 21, 79, 94, 337, 61, 483, 472, 228, 367, 262, 484, 409, 32, 253, 17, 157, 74, 466, 162, 200, 34, 322, 167, 373, 462, 354, 369, 95, 64, 65, 76, 240, 35, 349, 480, 53, 382, 252, 208, 492, 88, 321, 455, 412, 378, 298, 399] ,\n"
     ]
    }
   ],
   "source": [
    "bye_filt = []\n",
    "for f in bad_filt:\n",
    "    rem_filt = [k for k in Counter(torch.stack(f).view(-1).cpu().numpy()).keys()]\n",
    "    bye_filt.append(rem_filt)\n",
    "    print(rem_filt, ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[62, 47, 8, 3, 10],\n",
       " [70, 51, 99, 7, 6, 43, 75],\n",
       " [82, 56, 11, 48, 12, 54, 26],\n",
       " [135, 118, 107, 152, 40, 128, 186, 167, 240, 156, 143, 223, 105, 216],\n",
       " [95, 111, 4, 22, 104, 46, 107, 99, 91],\n",
       " [70, 119, 25, 100, 94, 39, 22, 73, 116],\n",
       " [203, 98, 80, 0, 199, 96, 239, 218, 166, 157, 146, 176, 13, 73],\n",
       " [126, 20, 89, 27, 7, 86, 3, 28, 16, 110],\n",
       " [112, 24, 82, 38, 0, 20],\n",
       " [22, 65, 15, 100, 179, 255, 217, 133, 71, 74, 169, 174, 82],\n",
       " [95, 113, 56, 78, 255, 250, 127, 74, 210, 197, 108, 121, 31, 129, 12],\n",
       " [82, 89, 95, 63, 246, 179, 129, 218, 70, 204, 18, 111, 103, 102, 174, 175],\n",
       " [468,\n",
       "  492,\n",
       "  277,\n",
       "  303,\n",
       "  353,\n",
       "  157,\n",
       "  365,\n",
       "  231,\n",
       "  481,\n",
       "  223,\n",
       "  508,\n",
       "  200,\n",
       "  262,\n",
       "  119,\n",
       "  66,\n",
       "  96,\n",
       "  35,\n",
       "  124,\n",
       "  479,\n",
       "  29,\n",
       "  291,\n",
       "  227,\n",
       "  182,\n",
       "  235,\n",
       "  245,\n",
       "  169,\n",
       "  472,\n",
       "  260,\n",
       "  22,\n",
       "  345,\n",
       "  382,\n",
       "  188],\n",
       " [109, 29, 145, 234, 100, 123, 16, 3, 193, 149, 178, 210, 200, 214, 141],\n",
       " [2, 227, 37, 17, 99, 186, 82, 161, 125, 217, 6, 79, 149],\n",
       " [300,\n",
       "  112,\n",
       "  293,\n",
       "  478,\n",
       "  414,\n",
       "  445,\n",
       "  397,\n",
       "  437,\n",
       "  338,\n",
       "  83,\n",
       "  498,\n",
       "  26,\n",
       "  477,\n",
       "  313,\n",
       "  257,\n",
       "  191,\n",
       "  149,\n",
       "  335,\n",
       "  140,\n",
       "  196,\n",
       "  373,\n",
       "  382,\n",
       "  428,\n",
       "  470,\n",
       "  347,\n",
       "  320,\n",
       "  71],\n",
       " [81, 254, 66, 78, 14, 38, 74, 140, 215, 89, 129, 95, 144, 105, 196],\n",
       " [50, 132, 71, 134, 199, 24, 106, 101, 1, 129, 165, 45, 158, 107, 26, 97],\n",
       " [131,\n",
       "  37,\n",
       "  125,\n",
       "  467,\n",
       "  40,\n",
       "  7,\n",
       "  166,\n",
       "  331,\n",
       "  14,\n",
       "  73,\n",
       "  5,\n",
       "  357,\n",
       "  265,\n",
       "  72,\n",
       "  478,\n",
       "  330,\n",
       "  284,\n",
       "  307,\n",
       "  208,\n",
       "  255,\n",
       "  164,\n",
       "  49,\n",
       "  340,\n",
       "  200,\n",
       "  309,\n",
       "  26,\n",
       "  382,\n",
       "  480,\n",
       "  276],\n",
       " [64, 21, 222, 171, 29, 197, 198, 57, 238, 92, 78, 210, 125, 141, 160],\n",
       " [51, 94, 251, 216, 148, 70, 173, 188, 46, 83, 132, 81, 175, 16, 86],\n",
       " [292,\n",
       "  125,\n",
       "  180,\n",
       "  249,\n",
       "  346,\n",
       "  1,\n",
       "  66,\n",
       "  72,\n",
       "  243,\n",
       "  173,\n",
       "  131,\n",
       "  450,\n",
       "  201,\n",
       "  258,\n",
       "  41,\n",
       "  89,\n",
       "  233,\n",
       "  336,\n",
       "  489,\n",
       "  115,\n",
       "  48,\n",
       "  107,\n",
       "  424,\n",
       "  495,\n",
       "  7,\n",
       "  435,\n",
       "  246,\n",
       "  174,\n",
       "  288,\n",
       "  359,\n",
       "  46,\n",
       "  331,\n",
       "  493]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bye_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 3, 53]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k in Counter(torch.stack(worst).view(-1).cpu().numpy()).keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
       " Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       " Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       " Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       " Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.min(torch.stack(imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 7, 7]) 4\n",
      "tensor([[[1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TuckerStructured(model.conv1, name='weight', amount=0, dim=-2,filt=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader = iter(valid_loader)\n",
    "x, y = next(dataloader)\n",
    "x = x.to(device)\n",
    "ny = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(x)\n",
    "nout = out.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "osample = nout[0]\n",
    "print(osample.is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorly/tucker_tensor.py:357: RuntimeWarning: Given only one int for 'rank' for decomposition a tensor of order 3. Using this rank for all modes.\n",
      "  warnings.warn(message, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "cp = dc.tucker(osample, 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(cp[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 15])\n",
      "torch.Size([28, 22])\n",
      "torch.Size([28, 22])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(cp[1])):\n",
    "    print(cp[1][i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = tl.cp_tensor.cp_to_tensor(cp)\n",
    "pred = tl.tucker_tensor.tucker_to_tensor(cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 28, 28])"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = torch.cdist(pred, osample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 28, 28])"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = torch.mean(dist, dim=[1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmin(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6711, 1.2247, 1.7894, 0.7869, 2.0999, 1.8570, 1.0078, 1.4888, 0.9308,\n",
       "        1.2620, 1.3241, 0.8901, 0.8965, 1.7836, 1.5718], device='cuda:0')"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7249, 1.8099, 1.4779, 1.0375, 2.1402, 1.5931, 1.0717, 1.4681, 1.1761,\n",
       "        1.3171, 1.2156, 1.6594, 1.1599, 2.0530, 1.3948], device='cuda:0')"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6309, 1.6372, 1.2259, 0.7888, 2.0096, 1.4350, 0.9153, 1.2241, 0.8291,\n",
      "        1.1813, 1.0735, 1.5589, 0.9121, 1.8906, 1.2141], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(7.8082, device='cuda:0')"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bigcp = cp\n",
    "# imp = importance\n",
    "print(imp)\n",
    "torch.mean(torch.cdist(bigcp[1][0], cp[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15, 22]), torch.Size([15, 22]))"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigcp[1][0].shape, cp[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.outer(torch.tensor(normalize([[1., 5, 0]])).squeeze(0),\n",
    "                torch.tensor(normalize([[1., 1, 1]])).squeeze(0))\n",
    "a += torch.outer(torch.tensor(normalize([[1., 50, 0]])).squeeze(0),\n",
    "                torch.tensor(normalize([[1., 1, 1]])).squeeze(0))\n",
    "c = torch.tensor(normalize([[0, 5, 1], [0, 5., 1], [5, 0, 5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorly/backend/core.py:885: UserWarning: In partial_svd: converting to NumPy. Check SVD_FUNS for available alternatives if you want to avoid this.\n",
      "  warnings.warn('In partial_svd: converting to NumPy.'\n"
     ]
    }
   ],
   "source": [
    "b = dc.parafac(c, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tl.cp_tensor.cp_to_tensor(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = torch.cdist(pred, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = torch.mean(dist, dim=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4884, 0.4884, 0.8133], dtype=torch.float64)"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0913, 0.9467, 0.2806],\n",
       "        [0.0913, 0.9467, 0.2806],\n",
       "        [0.0244, 0.2532, 0.0751]], dtype=torch.float64)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1289, 0.1289, 1.2072],\n",
       "        [0.1289, 0.1289, 1.2072],\n",
       "        [0.7378, 0.7378, 0.9642]], dtype=torch.float64)"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[5.0990],\n",
       "         [5.0990],\n",
       "         [5.0990]]),\n",
       " tensor([[0.0000],\n",
       "         [0.9806],\n",
       "         [0.1961]])]"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-8.m68",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m68"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

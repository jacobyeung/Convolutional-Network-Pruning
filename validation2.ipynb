{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d53a674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch, torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm\n",
    "device=\"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9859e1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('./data/tiny-imagenet-200')\n",
    "data_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4805, 0.4483, 0.3978), (0.263, 0.257, 0.267)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b88bfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_set = torchvision.datasets.ImageFolder(data_dir / 'val', data_transforms)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=8,\n",
    "                                           shuffle=True, num_workers=4, pin_memory=True)\n",
    "loss = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "967c6b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "model_path = 'outputs/best_models/resnet50/resnet50_adv_val_acc=0.7623.pt'\n",
    "model = torchvision.models.resnet50()\n",
    "model.fc = nn.Linear(2048, 200)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print('model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "305c0185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, dataset, dataloader, loss, device):\n",
    "    running_loss = 0.0\n",
    "    right = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for i, data in tqdm(enumerate(dataloader), total=len(dataset) / dataloader.batch_size):\n",
    "        data, y = data\n",
    "        data = data.to(device)\n",
    "        y = y.to(device)\n",
    "        ans = model.forward(data)\n",
    "        los = loss(ans, y)\n",
    "        running_loss += los.item()\n",
    "        right += torch.sum(torch.eq(torch.argmax(ans, dim=1), y))\n",
    "        total += y.shape[0]\n",
    "    return running_loss, running_loss / len(dataloader.dataset), right/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45888c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1250/1250.0 [00:46<00:00, 26.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7601000070571899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "valid_loss, avg_valid, valid_acc = valid(model, valid_set, valid_loader, loss, device)\n",
    "print('accuracy:', valid_acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8c17d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
